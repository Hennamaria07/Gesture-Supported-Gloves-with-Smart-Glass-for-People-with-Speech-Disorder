# Gesture-Supported-Gloves-with-Smart-Glass-for-People-with-Speech-Disorder
The aim of our project is to provide a solution to individuals with speech disorders who face difficulties in communicating effectively. This innovative project combines two technologies: gesture recognition and smart glasses, to create a novel communication system. In our system we describes a smart speaking glove to impart an easier means of communication between speech impaired people and normal people using synthesized speech.A smart glove is incorporated with flex sensors whose,resistance value changes according to the gesture specified by the user.This gesture information is processed by a micro-controller and corresponding voice output is given through a paired android device.Also a smart glass is provided which is connected with the hand gloves which will show the important text messages on the glass and also an accelerometer is provided within the glass for doing head movement detection, which can be also utilized for controles.We use MQTT protocol for transmission in this system. Sign language is a method used for communication by disabled person. Here we are converting sign language into text and then to speech, utilizing data gloves communication barrier between two different communities is eliminated. Using data gloves disabled person can also grow in their carrier and makes nation grow as percentage of disabled person are millions in count.

HOW TO IMPLEMENTMENT ?

Our project is divided into six modules: setting up smart gloves with flex sensors, programming smart gloves, creating machine learning models, and smart glasses and their display configuration. main python code and interface for connecting smart glasses, gloves, and main python code. A pair of glasses with a display unit that gives the user a visual interface for manipulating electronics make up the smart glass module. By establishing a Wi-Fi connection with a suitable device, the display unit may be configured. It's possible for the display unit to stand alone. The display device may be used to show the texts after it has been set up.
A person's capacity to make the sounds that form words is impacted by speech problems. In order to facilitate easier communication between speech-impaired persons and non-impaired people utilising synthesised speech, our approach describes a smart speaking glove. Flex sensors built into a smart glove have resistance values that alter based on the gesture the user specifies. This gesture data is analysed by a microcontroller, and a coupled Android device provides the accompanying vocal output.
Setting up the microcontroller to interpret the data from the flex sensors and transfer it to the main device is a necessary step in programming the smart gloves. The microcontroller's programming language is Arduino C programming. The programming must be built to instantly process and send data from the flex sensors to the main device.
The machine learning module entails the development of a machine learning model that can identify and decipher user-made hand gestures. A dataset of hand gestures and the accompanying activities is used to train the model. The dataset needs to be varied and inclusive of a variety of hand movements, including intricate actions involving many fingers. Python may be used to build the machine learning model, together with well-liked tools like Jupyter Notebook or Google Collab.
The primary Python code module acts as an interface between the machine learning and the smart glass and glove components. To show the necessary data on the smart glass after receiving data from the smart gloves, the code must be created. Using the machine learning model, it ought to be able to recognise hand gestures and carry out the corresponding actions on the gadget.
The core Python code may be interfaced with the smart glass and smart glove modules utilising Wi-Fi. To show the necessary data on the smart glass after receiving data from the smart gloves, the code must be created. Using the machine learning model, the code need to be able to recognise hand motions and carry out the relevant operations on the gadget.
In a wireless sensor network, a wormhole attack can interfere with routing and eventually worsen network performance. We have discussed many wormhole attack types and their methods of detection in this study. An active study field is wormhole identification in a dynamic WSN environment. Integration of trust-based systems and time- or distance-bounding wormhole detection methods is a promising research area for wormhole detection. A hands-free and simple user interface is offered by the implementation capabilities for controlling electrical equipment.

